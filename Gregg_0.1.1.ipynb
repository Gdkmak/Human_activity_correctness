{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Action Correctness Gregg_0.1 \n",
    "\n",
    "## CNN using 2D conv layers (batch, H, W, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from 'C:\\\\Users\\\\ghait\\\\Desktop\\\\MSc\\\\CS5500\\\\implementation\\\\Final\\\\utils.py'>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "import utils as u\n",
    "import importlib\n",
    "importlib.reload(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and interpolate the data in the shape [400x179x66]  [sample,frames, joints coordinates] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min:  28 , Max: 179\n"
     ]
    }
   ],
   "source": [
    "# get the highest number of frames that a sequence has \n",
    "path = 'C:/Users/ghait/Desktop/MSc/CS5500/Dataset/Kinect/*/*.txt'\n",
    "max_frm, min_frm = u.frame_max_min(path,\"hist\")\n",
    "print(\"Min: \", min_frm, \", Max:\",max_frm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dwonsample and Upsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [20:18<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Read the files and downsample or upsample to get equal size. \n",
    "Parameters:\n",
    "path -- locaiton of the dataset\n",
    "inter_method -- to choose the appropriate interpolation methods (upsampling):\n",
    "                The DEFAULT is POLYNOMIAL, and the others:\n",
    "                ‘linear’: Ignore the index and treat the values as equally spaced. \n",
    "                ‘time’: Works on daily and higher resolution data to interpolate given length of interval.\n",
    "                ‘index’, ‘values’: use the actual numerical values of the index.\n",
    "                ‘pad’: Fill in NaNs using existing values forwards.\n",
    "                ‘back_fill’ Fill in NaNs using existing values backwards.\n",
    "                ‘mean’ Fill in NaNs with mean value of predecessor and successor coordinate \n",
    "                ‘nearest’, ‘zero’, ‘slinear’, ‘quadratic’, ‘cubic’, ‘spline’, ‘barycentric’, ‘polynomial’: these functions are \n",
    "                passed to scipy.interpolate.interp1d. These methods use the numerical values of the index.\n",
    "                Both ‘polynomial’ and ‘spline’ require that you also specify an order (int), and it is 3 (cubic polynomial) (will explain why) \n",
    "sampling_method -- to choose either upsampling or downsampling. The DEFAULT is DOWNSAMPLING\n",
    "\"\"\"\n",
    "# upsampling / downsampling movements:\n",
    "_X, _Y = u.read_files(path, inter_method=\"zero\", sampling_method= \"upsampling\") # and Tqdam \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the files according to threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold:  [1.5376512028839273, 0.8725795904103362, 1.7296980273728368, 1.2286645396534837, 0.9544282889345874, 0.6832300905829993, 1.4480363554987576, 1.1307212789841568, 0.9541707242652826, 0.7332039982984807, 1.7307301186050685, 0.9790055177934811, 1.8345124061144742, 1.5244068690652626, 1.3419981846500197, 0.9504557075922091, 1.107993042796866, 0.9423634376575284, 0.7815489904094671, 0.8142873843301711]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2000/2000 [02:16<00:00, 13.62it/s]\n"
     ]
    }
   ],
   "source": [
    "# Threshold approach\n",
    "_X, _Y = u.read_files_threshold(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the files and according to the lowest number of frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 2000/2000 [00:03<00:00, 645.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# read according to the lowest number of frames \n",
    "_X, _Y = u.read_files_lowest(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored '_X' (ndarray)\n",
      "Stored '_Y' (ndarray)\n"
     ]
    }
   ],
   "source": [
    "# Store _X and _Y to be used in different notebooks\n",
    "%store _X\n",
    "%store _Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 179, 66, 1)\n",
      "(2000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Add one more dimension to create a tensor that will be fed to CNN\n",
    "num_joint = _X.shape[2] \n",
    "num_frm = _X.shape[1]\n",
    "num_file = _X.shape[0]\n",
    "\n",
    "temp = np.zeros((num_file,1,num_frm,num_joint))\n",
    "for h in range(num_file):\n",
    "    temp[h][0][:][:] = _X[h,:,:]\n",
    "\n",
    "X_4d = temp \n",
    "\n",
    "# Reshape it to have 4 D shape such as (m, H, W, C) where C is number of channel\n",
    "X_4d = np.rollaxis(np.rollaxis(X_4d, 2, 1),3,2) \n",
    "print(X_4d.shape)\n",
    "print(_Y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_min = X_4d.min(axis=(1, 2), keepdims=True)\n",
    "X_max = X_4d.max(axis=(1, 2), keepdims=True)\n",
    "X_norm = (X_4d - X_min)/(X_max-X_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stand = []\n",
    "for i in range (len(X_4d)):\n",
    "    numerator = X_4d[i,:,:,0] - np.mean(X_4d[i,:,:,0], axis=0)\n",
    "    denominator = np.std(X_4d[i,:,:,0], axis=0)\n",
    "    temp = np.divide(numerator, denominator, out=np.zeros_like(numerator), where=denominator!=0) # avoid division on zero\n",
    "    X_stand.append(temp)\n",
    "X_stand = np.array(X_stand)\n",
    "X_stand = X_stand[:,:,:,np.newaxis] # because the results were in 3D array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Spliting the data Cross Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1800, 179, 66, 1)\n",
      "(200, 179, 66, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Any of these tensors can be an input for the function below \n",
    "X_norm -- normalised \n",
    "X_stand -- standardised \n",
    "X_4d -- original data without any manipulation \n",
    "\"\"\"\n",
    "import importlib\n",
    "importlib.reload(u)\n",
    "# this function split the dataset to training and test set\n",
    "X_trn,Y_trn,X_tst,Y_tst = u.train_test(X_stand, _Y) \n",
    "print(X_trn.shape)\n",
    "print(X_tst.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to one- hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_tst\n",
    "X_train = X_trn\n",
    "Y_train = u.convert_to_one_hot(Y_trn[:,2],2).T\n",
    "Y_test = u.convert_to_one_hot(Y_tst[:,2], 2).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch shape (taining and test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples = 1800\n",
      "Number of test examples = 200\n",
      "X_train shape: (1800, 179, 66, 1)\n",
      "Y_train shape: (1800, 2)\n",
      "X_test shape: (200, 179, 66, 1)\n",
      "Y_test shape: (200, 2)\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"Number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D CNN Model"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The following section was supposed to implement AlexNet architecture that has five-layer ConvNet in Tensorflow:\n",
    "\n",
    "Layer 1 (CONV2D -> RELU -> MAXPOOL) -> W1 = [6, 6, 1, 96] with 3 strides and 0 padding    -> \n",
    "Layer 2 (CONV2D -> RELU -> MAXPOOL) -> W2 = [3, 3, 96, 256] with 1 strides and 0 padding  -> \n",
    "Layer 3 (CONV2D -> RELU)            -> W3 = [2, 2, 256, 348] with 1 strides and 0 padding -> \n",
    "Layer 4 (CONV2D -> RELU)            -> W4 = [2, 2, 348, 348] with 1 strides and 0 padding -> \n",
    "Layer 5 (CONV2D -> RELU)            -> W5 = [2, 2, 348, 256] with 1 strides and 0 padding -> \n",
    "\n",
    "FLATTEN -> FULLYCONNECTED ->  FULLYCONNECTED -> SOFTMAX\n",
    "\n",
    "\"ADD IMAGE OF THE ARCHITECTURE\" https://neurohive.io/wp-content/uploads/2018/10/AlexNet-1.png \n",
    "\n",
    "HOWEVER, due of the lack of processing and since the research doesn't focus on the architecture of the model, the architecture\n",
    "was simplified to have only two-layer ConvNet and one FULLYCONNECTED:\n",
    "\n",
    "CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> FULLYCONNECTED -> SOFTMAX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'conv' from 'C:\\\\Users\\\\ghait\\\\Desktop\\\\MSc\\\\CS5500\\\\implementation\\\\Final\\\\conv.py'>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import conv as cnn\n",
    "importlib.reload(cnn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 0.682689\n",
      "Cost after epoch 5: 0.377649\n",
      "Cost after epoch 10: 0.207221\n",
      "Cost after epoch 15: 0.132529\n",
      "Cost after epoch 20: 0.083386\n",
      "Cost after epoch 25: 0.052899\n",
      "Cost after epoch 30: 0.039478\n",
      "Cost after epoch 35: 0.024491\n",
      "Cost after epoch 40: 0.016527\n",
      "Cost after epoch 45: 0.011473\n",
      "Cost after epoch 50: 0.009055\n",
      "Cost after epoch 55: 0.006632\n",
      "Cost after epoch 60: 0.004870\n",
      "Cost after epoch 65: 0.003850\n",
      "Cost after epoch 70: 0.003018\n",
      "Cost after epoch 75: 0.002569\n",
      "Cost after epoch 80: 0.002100\n",
      "Cost after epoch 85: 0.001730\n",
      "Cost after epoch 90: 0.001433\n",
      "Cost after epoch 95: 0.001296\n",
      "Cost after epoch 100: 0.001033\n",
      "Cost after epoch 105: 0.000893\n",
      "Cost after epoch 110: 0.000777\n",
      "Cost after epoch 115: 0.000663\n",
      "Cost after epoch 120: 0.000574\n",
      "Cost after epoch 125: 0.000496\n",
      "Cost after epoch 130: 0.000428\n",
      "Cost after epoch 135: 0.000378\n",
      "Cost after epoch 140: 0.000323\n",
      "Cost after epoch 145: 0.000282\n",
      "Cost after epoch 150: 0.000254\n",
      "Cost after epoch 155: 0.000224\n",
      "Cost after epoch 160: 0.000197\n",
      "Cost after epoch 165: 0.000174\n",
      "Cost after epoch 170: 0.000153\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-e49001ee25b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;33m(\u001b[0m\u001b[0mminibatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminibatch_Y\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m             \u001b[1;31m# Run the session to execute the optimizer and the cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m             \u001b[0m_\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtemp_cost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcost\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mminibatch_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mminibatch_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m             \u001b[0mminibatch_cost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtemp_cost\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnum_minibatches\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ghait\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    948\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 950\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    951\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    952\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ghait\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1171\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1172\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1173\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1174\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ghait\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1348\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1349\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1350\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1352\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ghait\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1354\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1355\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1356\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1357\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ghait\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1339\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1340\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1341\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1342\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\ghait\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1428\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# initialise parameters \n",
    "\n",
    "learning_rate = 0.0009    # learning_rate -- learning rate of the optimization\n",
    "num_epochs = 200           # num_epochs -- number of epochs of the optimization loop\n",
    "minibatch_size = 50       # minibatch_size -- size of a minibatch\n",
    "print_cost = True         # print_cost -- True to print the cost every 100 epochs\n",
    "    \n",
    "ops.reset_default_graph() # to be able to rerun the model without overwriting tf variables\n",
    "tf.set_random_seed(1)     # to keep results consistent (tensorflow seed)\n",
    "seed = 3                  # to keep results consistent (numpy seed)\n",
    "(m, n_H0, n_W0, n_C0) = X_train.shape             \n",
    "n_y = Y_train.shape[1]                            \n",
    "costs = []                # To keep track of the cost\n",
    "\n",
    "# Create Placeholders of the correct shape\n",
    "X, Y = cnn.create_placeholders(n_H0, n_W0, n_C0, n_y)\n",
    "\n",
    "# Initialize tf parameters\n",
    "parameters = cnn.initialize_parameters()\n",
    "\n",
    "# Forward propagation: Build the forward propagation in the tensorflow graph\n",
    "Z3 = cnn.forward_propagation(X, parameters)\n",
    "\n",
    "# Cost function: Add cost function to tensorflow graph\n",
    "cost = cnn.compute_cost(Z3, Y)\n",
    "\n",
    "# Backpropagation: Define the tensorflow optimizer. Use an AdamOptimizer that minimizes the cost\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "# Initialize all the variables globally\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Start the session to compute the tensorflow graph\n",
    "with tf.Session() as sess:\n",
    "    # Run the initialization\n",
    "    sess.run(init)\n",
    "    # Do the training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        minibatch_cost = 0.\n",
    "        num_minibatches = int(m / minibatch_size) # number of minibatches of size minibatch_size in the train set\n",
    "        seed = seed + 1\n",
    "        minibatches = cnn.random_mini_batches(X_train, Y_train, minibatch_size, seed)\n",
    "\n",
    "        for minibatch in minibatches:\n",
    "            # Select a minibatch\n",
    "            (minibatch_X, minibatch_Y) = minibatch\n",
    "            # Run the session to execute the optimizer and the cost\n",
    "            _ , temp_cost = sess.run([optimizer, cost], feed_dict={X:minibatch_X, Y:minibatch_Y})\n",
    "            minibatch_cost += temp_cost / num_minibatches\n",
    "            \n",
    "        # Print the cost every 5 epochs\n",
    "        if print_cost == True and epoch % 5 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" % (epoch, minibatch_cost))\n",
    "        if print_cost == True and epoch % 1 == 0:\n",
    "            costs.append(minibatch_cost)\n",
    "\n",
    "    # Plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate the correct predictions\n",
    "    predict_op = tf.argmax(Z3, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y, 1))\n",
    "    \n",
    "    # Evaluate the model\n",
    "    # Calculate accuracy on the test set\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    train_accuracy = accuracy.eval({X: X_train, Y: Y_train})\n",
    "    test_accuracy = accuracy.eval({X: X_test, Y: Y_test})\n",
    "\n",
    "    print('Train Accuracy:  %.2f%%' % (train_accuracy*100))\n",
    "    print('Test Accuracy:  %.2f%%' % (test_accuracy*100))\n",
    "\n",
    "    # confusioion matrix--- work on it later\n",
    "    \n",
    "    pre = predict_op.eval({X: X_test, Y: Y_test})\n",
    "    print(\"Prediction: \", pre, \"\\nActual :\", Y_tst[:,2])\n",
    "    \n",
    "    confusion = tf.confusion_matrix(labels=Y_tst[:,2], predictions=pre, num_classes=2)\n",
    "    print(\"Confusion matrix\\n\", confusion.eval(session=sess))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
